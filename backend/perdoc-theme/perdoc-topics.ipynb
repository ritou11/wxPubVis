{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf-8')   \n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora import Dictionary\n",
    "import os\n",
    "from pprint import pprint\n",
    "import jieba\n",
    "\n",
    "def load_stopwords():\n",
    "    f_stop = open('stop_words.txt', 'r')\n",
    "    sw = [line.strip() for line in f_stop]\n",
    "    f_stop.close()\n",
    "    return sw\n",
    "\n",
    "#分词+过滤停用词\n",
    "\n",
    "def word_cut(text):\n",
    "    text = str(text)\n",
    "    seg = jieba.cut(text.strip())\n",
    "    outstr = \"\"\n",
    "    for word in seg:  \n",
    "            if word not in stopwords:  \n",
    "                if word != '\\t':  \n",
    "                    outstr += word  \n",
    "                    outstr += \" \"  \n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "from pymongo import MongoClient\n",
    "#连接数据库\n",
    "conn = MongoClient(\"mongodb://127.0.0.1:27017\")\n",
    "db = conn.wechat_spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>digest</th>\n",
       "      <th>pid</th>\n",
       "      <th>pubname</th>\n",
       "      <th>readNum</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>洞见（DJ00123987）——不一样的观点，不一样的故事，1000万人订阅的微信大号。点击...</td>\n",
       "      <td>不是每一种观点，都可以叫洞见</td>\n",
       "      <td>5ce1507c4877ed43338112e1</td>\n",
       "      <td>洞见</td>\n",
       "      <td>100001</td>\n",
       "      <td>进了985、211才知道：优秀的朋友圈，有多重要？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>洞见（DJ00123987）——不一样的观点，不一样的故事，1000万人订阅的微信大号。点击...</td>\n",
       "      <td>不是每一种观点，都可以叫洞见</td>\n",
       "      <td>5ce1507c4877ed43338112e7</td>\n",
       "      <td>洞见</td>\n",
       "      <td>100001</td>\n",
       "      <td>长相年轻，是因为这五点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>洞见（DJ00123987）——不一样的观点，不一样的故事，1000万人订阅的微信大号。点击...</td>\n",
       "      <td>不是每一种观点，都可以叫洞见</td>\n",
       "      <td>5ce1507c4877ed43338112e9</td>\n",
       "      <td>洞见</td>\n",
       "      <td>100001</td>\n",
       "      <td>所有遇见，皆是天意</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>洞见（DJ00123987）——不一样的观点，不一样的故事，1000万人订阅的微信大号。点击...</td>\n",
       "      <td>不是每一种观点，都可以叫洞见</td>\n",
       "      <td>5ce1507c4877ed43338112eb</td>\n",
       "      <td>洞见</td>\n",
       "      <td>96569</td>\n",
       "      <td>深夜10点，95分钟“生命对话”：谢谢你，陌生人！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>洞见（DJ00123987）——不一样的观点，不一样的故事，1000万人订阅的微信大号。点击...</td>\n",
       "      <td>不是每一种观点，都可以叫洞见</td>\n",
       "      <td>5ce1507c4877ed43338112ed</td>\n",
       "      <td>洞见</td>\n",
       "      <td>100001</td>\n",
       "      <td>102岁贝聿铭去世：中国唯一富过15代的家族，家训只有30个字</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content          digest  \\\n",
       "0  ���������DJ00123987���������������������������������������������������1000������������������������������������...  ������������������������������������������   \n",
       "1  ���������DJ00123987���������������������������������������������������1000������������������������������������...  ������������������������������������������   \n",
       "2  ���������DJ00123987���������������������������������������������������1000������������������������������������...  ������������������������������������������   \n",
       "3  ���������DJ00123987���������������������������������������������������1000������������������������������������...  ������������������������������������������   \n",
       "4  ���������DJ00123987���������������������������������������������������1000������������������������������������...  ������������������������������������������   \n",
       "\n",
       "                        pid pubname readNum                            title  \n",
       "0  5ce1507c4877ed43338112e1      ������  100001        ������985���211������������������������������������������������  \n",
       "1  5ce1507c4877ed43338112e7      ������  100001                      ���������������������������������  \n",
       "2  5ce1507c4877ed43338112e9      ������  100001                        ���������������������������  \n",
       "3  5ce1507c4877ed43338112eb      ������   96569        ������10������95���������������������������������������������������  \n",
       "4  5ce1507c4877ed43338112ed      ������  100001  102���������������������������������������15���������������������������30������  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pstcol = db.posts\n",
    "cursor = pstcol.find(no_cursor_timeout=True)\n",
    "\n",
    "pid = []\n",
    "pubname = []\n",
    "tit = []\n",
    "dig = []\n",
    "con = []\n",
    "readNum = []\n",
    "\n",
    "for i, s in enumerate(cursor):\n",
    "    print(str(s['title']))\n",
    "    print('\\n')\n",
    "    if s.has_key('content'):\n",
    "        if s['msgBiz'] ==\"MjM5MDc0NTY2OA==\":\n",
    "            pubname.append(str('洞见'))\n",
    "        elif s['msgBiz'] == \"MzUxODM4OTYzMg==\":\n",
    "            pubname.append(str('清华小五爷园'))\n",
    "        elif s['msgBiz'] == \"MzA4MjEyNTA5Mw==\":\n",
    "            pubname.append(str('Python开发者'))\n",
    "        elif s['msgBiz'] == \"MzI1NDY5NDM3OQ==\":\n",
    "            pubname.append(str('凤凰WEEKLY'))\n",
    "        else:\n",
    "            pubname.append(str('沃顿商业'))\n",
    "        pid.append(str(s['_id']))\n",
    "        tit.append(str(s['title']))\n",
    "        dig.append(str(s['digest']))\n",
    "        con.append(str(s['content']))\n",
    "        if s.has_key('readNum'):\n",
    "            readNum.append(str(s['readNum']))\n",
    "        else:\n",
    "            readNum.append(0)\n",
    "dic = {\"pid\":pid,\n",
    "        \"pubname\":pubname,\n",
    "        \"title\":tit,\n",
    "       \"digest\":dig,\n",
    "       \"content\":con,\n",
    "      \"readNum\":readNum}\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = df['title'] + df['content']\n",
    "\n",
    "stopwords = load_stopwords()\n",
    "\n",
    "df[\"con\"] = con\n",
    "\n",
    "df[\"con_cutted\"] = df.con.apply(word_cut)\n",
    "\n",
    "df.con_cutted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每一个单词关联一个唯一的ID\n",
    "docs = [ [word for word in df.con_cutted[i].split() ] for i in range(0,len(df)) ]\n",
    "word_count_dict = Dictionary(docs)\n",
    "#过滤高频低频词\n",
    "word_count_dict.filter_extremes(no_below=5, no_above=0.5) \n",
    "#将文档表示成词袋向量\n",
    "bag_of_words_corpus = [word_count_dict.doc2bow(perdoc) for perdoc in docs] \n",
    "\n",
    "#保存模型\n",
    "model_name = \"./model.lda\"  \n",
    "if os.path.exists(model_name):\n",
    "    lda_model = gensim.models.LdaModel.load(model_name)  \n",
    "    print(\"loaded from old\")\n",
    "else:\n",
    "    # preprocess()  第一个参数为选用的文档向量，num_topics为主题个数，id2word可选是选用的字典，\n",
    "    lda_model = gensim.models.LdaModel(bag_of_words_corpus, num_topics=80, id2word=word_count_dict)\n",
    "    lda_model.save(model_name)  \n",
    "    print(\"loaded from new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{pid:pid, theme: “主题1”, words: [{name:”xxx”, freq:123}], weight}\n",
    "\n",
    "perdoc = db.perdoc\n",
    "topic_num=3\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    doc = [ word for word in df.con_cutted[i].split() ]\n",
    "    doc_dict = word_count_dict.doc2bow(doc)\n",
    "    result=lda_model[doc_dict]\n",
    "    result=sorted(result,key=lambda tup: -1 * tup[1])#排序，只取前三的主题\n",
    "    idx = 1\n",
    "    dict = {}\n",
    "    dict['pid'] = str(df['pid'][i])\n",
    "    print(\"文章\"+str(i+1))\n",
    "    for topic in result:\n",
    "        if idx>topic_num:\n",
    "            break\n",
    "        #print_topic(x,y) x是主题的id，y是打印该主题的前y个词，词是按权重排好序的\n",
    "        dict['theme'] = str(\"主题\"+str(idx))\n",
    "        print(\"主题\"+str(idx))\n",
    "        dict['weight'] = str(topic[1])\n",
    "        s = str(lda_model.print_topic(topic[0], 30))\n",
    "        freq_word = s.split(\" + \")\n",
    "        for j in range(0,len(freq_word)):\n",
    "            fw = freq_word[j].split(\"*\")\n",
    "            if dict.has_key('words'):\n",
    "                dict['words'].append({'name':str(fw[1]), 'freq':fw[0]})\n",
    "            else:\n",
    "                dict['words'] = [{'name':str(fw[1]), 'freq':fw[0]}]\n",
    "        idx += 1\n",
    "        #print(dict)\n",
    "        result = perdoc.insert_one(dict)\n",
    "        #print(result)\n",
    "#print(db.perdoc.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{pid:待查询文章id, sid:匹配文章id, similarity:pid和sid两篇文章相似度}\n",
    "#每篇文章的相似列表\n",
    "sim = db.sim\n",
    "\n",
    "from gensim import corpora, similarities\n",
    "import traceback\n",
    "# 用bag_of_words_corpus作为特征，训练tf_idf_model\n",
    "tf_idf_model = gensim.models.TfidfModel(bag_of_words_corpus)\n",
    "\n",
    "# 每篇文章在vsm上的tf-idf表示\n",
    "corpus_tfidf = tf_idf_model[bag_of_words_corpus]\n",
    "\n",
    "def similarity( i, query, dictionary, corpus_tfidf ):\n",
    "    try:\n",
    "\n",
    "        # 建立索引\n",
    "        index = similarities.MatrixSimilarity(corpus_tfidf)\n",
    "\n",
    "        # 在dictionary建立query的vsm_tf表示\n",
    "        query_bow = dictionary.doc2bow( query.lower().split() )\n",
    "\n",
    "        # 查询在n_topics维空间的表示\n",
    "        query_lda = tf_idf_model[query_bow]\n",
    "\n",
    "        # 计算相似度\n",
    "        simi = index[query_lda]\n",
    "        query_simi_list = []\n",
    "        for idx, item in enumerate(simi):\n",
    "            if idx != i :\n",
    "                query_simi_list.append( {'pid':str(df['pid'][i]), 'sid':str(df['pid'][idx]), 'similarity':str(item)} )\n",
    "        result = sim.insert_many(query_simi_list)\n",
    "        \n",
    "    except Exception,e:\n",
    "        print traceback.print_exc()\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    print(\"相似权重矩阵：\")\n",
    "    similarity(i, str(df.con_cutted[i]), word_count_dict, corpus_tfidf )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
